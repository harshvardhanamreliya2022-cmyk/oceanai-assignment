# QA Agent Environment Configuration
# Copy this file to .env and fill in your values

# =================================
# LLM Provider Configuration
# =================================
# Choose your LLM provider: groq, ollama, or openai
LLM_PROVIDER=groq

# Groq Configuration (recommended)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=mixtral-8x7b-32768

# Ollama Configuration (local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# OpenAI Configuration (optional)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# =================================
# Application Settings
# =================================
DEBUG=False
LOG_LEVEL=INFO

# =================================
# Paths (defaults are usually fine)
# =================================
VECTORDB_PATH=./data/vectordb
UPLOAD_DIR=./data/uploads
SCRIPTS_DIR=./data/scripts
LOG_DIR=./data/logs

# =================================
# Processing Settings
# =================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=5
